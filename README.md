# Background

I've never written a single line of Go before 4 days ago. Please excuse my coding style if they are not idiomatic or not correct.

# Requirements

1. docker
2. docker-compose

# Setup

1. Run `docker-compose build server` to build the base image.
2. Run `docker-compose up updatefile`. Wait until you see `Ready to serve API` appears in the log.
3. Run `docker-compose up server`.
4. Run `docker-compose up test` to run the unit tests.

# Swagger

1. Swagger spec is located inside `/docs`. It is autogenerated.

# Caching strategies for /characters API

## Context

1. Data from Marvel's /characters API is paginated and requires multiple requests to get the complete list
2. A few assumptions were made regarding the nature of the API:
    - Marvel will not remove character, only add.
    - Data has to be sorted in the request. Therefore, a new character can appear in any of the paginated requests.
3. Marvel also provides `Total` in the API response. This value is static across the paginated requests. This seems to be
a reliable indicator to decide whether to update the cache or not.

## Strategies considered

### Direct caching on API request

In this approach, both logic for reading and updating cache are done during the request to the `/characters` endpoint
The cache is stored in some kind of storage, e.g in-memory or redis.

#### Warm up

Ideally the cache is "warm" before the server can start serving requests. Using external storage such as redis would be
more suitable for warming up the cache. A script can be created to check if cache is empty and then begin populating it
with data from Marvel API

#### Reading

All requests to `/characters` will trigger requests to the cache. If it is in-memory cache, it will be faster. Using
external storage such as redis will impose certain penalty to the request, not to mention another potential point of
networking failure.

#### Updating

Cache needs to be checked if it is outdated. One option could be taken is:

1. Set an interval after which a request will be made to Marvel API to get the latest value of `Total`. A last updated
value can be stored together in the cache and the interval can be calculated using that value.
2. Check the response from Marvel and compare the value of `Total`. If it is the same, update the `last updated` field.
Otherwise, update the cache.

The check of cache validality can be done in the API during the request. To update the cache, it can either be done
in the same request, which will cause latency penalty. Alternatively, a background worker can be triggered to do the
update.

#### Problem

Mixing the reading and updating logic into the request code causes a few problems:

1. Latency due to cache check and update. If multiple requests came at the same time and all requests does the checking and
updating at the same time, multiple requests will be slow.
2. Concurrently updating the cache might cause issue. Some storage might lock the storage during update in order to
maintain consistency.
3. Race condition. If Marvel somehow update the character list multiple times within a short period of time AND the `Total`
value also changes during the period, there is a possibility that multiple instance of requests has a different world view
of the data from Marvel. If multiple updates are done together concurrently, there is possibility that a stale version
of the data wins and our API will end up with outdated data without knowing about it.

### Separate cache reader and writer

This is the strategy adopted in this code base.

One of the best way to both ensure strong consistency and high availability is to split the readers and writer. A single
writer for a single object (a list of character id can be considered as a single object) can avoid concurrency issues.
Since readers (API) does not do anything much, it can serve a lot more requests faster.

In our case, the writer is a single script being triggered at an interval to check the cache validity as well updating it.
The cache storage of choice is a json file. When the script decides that the cache needs to be updated, the content is 
first written to a temporary file. This way, it will not impact or lock the main file that is used for serving the API.
When the write is complete, the file is moved to the target location.

Since the cache is a file, the content can be served as a static file. This opens further opportunities for other
optimization related to serving static files.

#### Warm Up

Before the API can serve request, the script has to run to populate the cache-file. Once it is done, the server can start

#### Reading

Served as static json file

#### Updating

Cronjob runs separately that runs the script again in certain schedule. The script will check the `Total` value and
decide if the cache should be updated or not. If yes, the data is first written to temporary file and then moved to the
target location.

#### Problem

Since file is used as cache and at the moment it is served from the filesystem. The filesystem will be the bottleneck
as the number of requests increases. But, as mention, static file strategy allows for other alternative approaches.
Something akin to CDN comes to mind.

Multiple script can be triggered accidentally at the same time. Therefore introducing concurrency issue that we would like
to avoid. A few things can be done to prevent this, namely using lock file. If a lock exists, then other other scripts will
just terminate and not run. Of course, lock file have issues of its own.

Since script runs in the background, it has to be monitored somehow and notify when there's something wrong.
